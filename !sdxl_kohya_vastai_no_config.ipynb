{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5194f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDXL Dreambooth Training With Kohya_SS SD-Scripts - No-config version\n",
    "# Run each cell in sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9888623-b6f4-4bd9-aa2d-e1234345991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. INSTALL DEPENDENCIES\n",
    "\n",
    "!wget https://raw.githubusercontent.com/yushan777/kohya_ss_vastai/main/colors.py -q\n",
    "from colors import bcolors\n",
    "from IPython.display import clear_output\n",
    "!apt-get update -y && apt-get install -y libgl1\n",
    "!sudo apt update -y && sudo apt install -y python3-tk\n",
    "clear_output(wait=True)\n",
    "\n",
    "print(f\"{bcolors.BOLD}{bcolors.GREEN}Installing dependencies - this will take a few minutes...{bcolors.ENDC}\")\n",
    "print(f\"{bcolors.BOLD}{bcolors.GREEN}Ignore any warnings about running pip as the 'root'{bcolors.ENDC}\")\n",
    "!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 --extra-index-url https://download.pytorch.org/whl/cu118 --root-user-action=ignore # no_verify leave this to specify not checking this a verification stage\n",
    "!pip install xformers==0.0.20 bitsandbytes==0.35.0 --root-user-action=ignore\n",
    "!pip install tensorboard==2.12.3 tensorflow==2.12.0 wheel --root-user-action=ignore\n",
    "!pip install protobuf==3.20.3 --root-user-action=ignore\n",
    "!pip install tensorrt --root-user-action=ignore\n",
    "!pip install gdown --root-user-action=ignore\n",
    "!pip install github-clone --root-user-action=ignore\n",
    "!pip install accelerate==0.19.0 --root-user-action=ignore\n",
    "!pip install transformers==4.30.2 --root-user-action=ignore\n",
    "!pip install diffusers[torch]==0.18.2 --root-user-action=ignore\n",
    "!pip install ftfy==6.1.1 --root-user-action=ignore\n",
    "!pip install albumentations==1.3.0 --root-user-action=ignore\n",
    "!pip install opencv-python==4.7.0.68 --root-user-action=ignore\n",
    "!pip install einops==0.6.0 --root-user-action=ignore\n",
    "!pip install pytorch-lightning==1.9.0 --root-user-action=ignore\n",
    "!pip install bitsandbytes==0.35.0 --root-user-action=ignore\n",
    "!pip install tensorboard==2.12.0 --root-user-action=ignore\n",
    "!pip install safetensors==0.3.1 --root-user-action=ignore\n",
    "!pip install altair==4.2.2 --root-user-action=ignore\n",
    "!pip install easygui==0.98.3 --root-user-action=ignore\n",
    "!pip install toml==0.10.2 --root-user-action=ignore\n",
    "!pip install voluptuous==0.13.1 --root-user-action=ignore\n",
    "!pip install huggingface-hub==0.15.1 --root-user-action=ignore\n",
    "!pip install invisible-watermark==0.2.0  --root-user-action=ignore\n",
    "!pip install open-clip-torch==2.20.0 --root-user-action=ignore\n",
    "!pip install protobuf==3.20.3 --root-user-action=ignore\n",
    "!pip install -e . --root-user-action=ignore\n",
    "clear_output(wait=True)\n",
    "print(f\"{bcolors.BOLD}{bcolors.GREEN}Finished installing dependencies.{bcolors.ENDC}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197e5f03-f37d-4a75-bd3c-b4ffd5b62833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. VARIABLES\n",
    "# The following variables can be changed according to your project preferences\n",
    "token_word = \"ohwx\"\n",
    "class_word = \"person\" \n",
    "training_repeats = 40\n",
    "training_root_dir = \"training_images\" \n",
    "regularization_root_dir = \"reg_images\"\n",
    "models_dir = \"training_models\"\n",
    "project_name = \"myProject\"\n",
    "output_dir = \"trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db7f292-afe1-4cdd-b639-edb2d14d6bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CREATE DATASET FOLDERS & MODEL FOLDER\n",
    "\n",
    "# ================================================================\n",
    "# your training and reg image subfolders will be named according to what is set in previous cell: \n",
    "# so if you stuck with the defaults, they would be for example :\n",
    "# \"training_images/40_ohwx person\"\n",
    "# \"reg_images/1_person\"\n",
    "training_dir = f'{training_root_dir}/{training_repeats}_{token_word} {class_word}'\n",
    "reg_dir = f'{regularization_root_dir}/1_{class_word}'\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss\n",
    "\n",
    "import os\n",
    "if os.path.exists(training_dir) == False:\n",
    "  os.makedirs(training_dir)\n",
    "  print(f'{training_dir} Created.')\n",
    "else:\n",
    "  print(f'{training_dir} already exists.')\n",
    "\n",
    "if os.path.exists(reg_dir) == False:\n",
    "  os.makedirs(reg_dir)\n",
    "  print(f'{reg_dir} Created.')\n",
    "else:\n",
    "  print(f'{reg_dir} already exists.')\n",
    "\n",
    "if os.path.exists(models_dir) == False:\n",
    "  os.makedirs(models_dir)\n",
    "  print(f'{models_dir} Created.')\n",
    "else:\n",
    "  print(f'{models_dir} already exists.')\n",
    "\n",
    "# Create prompt file use for samples during training. \n",
    "# first 2 prompts are the same but one has CFG=1 and the other CFG=7\n",
    "# if subject likeness is strong and regular even at CFG=1 then it is an good indicator that it is overfitted\n",
    "# third prompt is to check how well it responds to styling. \n",
    "lines = [\n",
    "    f\"a photo of {token_word} {class_word} --w 1024 --h 1024 --l 7, --s 20 --d 1234567890\\n\",\n",
    "    f\"a photo of {token_word} {class_word} --w 1024 --h 1024 --l 1, --s 20 --d 1234567890\\n\",\n",
    "    f\"a portrait of {token_word} {class_word} in the style of Rembrandt --w 1024 --h 1024 --l 6, --s 20 --d 1234567890\\n\"\n",
    "]\n",
    "\n",
    "# Create and write to the text file\n",
    "with open(\"prompt.txt\", \"w\") as file:\n",
    "    file.writelines(lines)\n",
    "\n",
    "print(\"File 'prompt.txt' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16769aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Download and unzip Training Images to Training Image folder\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss\n",
    "\n",
    "# =================================================================\n",
    "# Use YOUR OWN Google Drive file IDs for your image zips\n",
    "training_images_file_ID = '1BIixbqMYW5-eOvTFC_xxxxxlnBzey-0' \n",
    "# =================================================================\n",
    "\n",
    "# download training images from google drive, rename to train.zip\n",
    "!gdown '{training_images_file_ID}' -O train.zip\n",
    "\n",
    "# move train.zip to training images sub folder\n",
    "shutil.move('train.zip', f'{training_dir}')\n",
    "\n",
    "# extract zip contents to current folder and delete zip\n",
    "%cd $training_dir\n",
    "with zipfile.ZipFile('train.zip', 'r') as train_ref:\n",
    "    train_ref.extractall()\n",
    "\n",
    "# delete zip\n",
    "!rm train.zip\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3628554f",
   "metadata": {},
   "source": [
    "## For Regularization Images, you have 2 choices: \n",
    "1) Download your own regularization images (google drive) : use Cell 5a. <br/>\n",
    "or\n",
    "2) Download a set (if class is appropriate) from my github repo. : use Cell 5b. <br/> \n",
    "Sets available : person_ddim, woman_ddim, man_ddim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02061da7-5923-4b79-ac3b-daa493d20337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a. Download YOUR OWN Reg Images (Google Drive)\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss\n",
    "\n",
    "# =================================================================\n",
    "# Use YOUR OWN Google Drive file IDs for your image zips\n",
    "reg_images_file_ID = '1CIqOhLBfzrl5OkvGgbp2XK_xxxxxxx5bMw'\n",
    "# =================================================================\n",
    "\n",
    "# download reg images from google drive, rename to reg.zip\n",
    "!gdown '{reg_images_file_ID}' -O reg.zip\n",
    "\n",
    "# move train.zip to reg images sub folder\n",
    "shutil.move('reg.zip', f'{reg_dir}')\n",
    "\n",
    "# extract zip contents to current folder and delete zip\n",
    "%cd $reg_dir\n",
    "with zipfile.ZipFile('reg.zip', 'r') as reg_ref:\n",
    "    reg_ref.extractall()\n",
    "\n",
    "# delete zip\n",
    "!rm reg.zip\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f43fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b. Download one of my pre-made set of regularization images\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# back to parent folder\n",
    "%cd /workspace/kohya_ss\n",
    "\n",
    "print(\"This might take a few minutes.\")\n",
    "orig_dir_name = ''\n",
    "if class_word == 'person':\n",
    "    !ghclone https://github.com/yushan777/SD-Regularization-Images/tree/main/sdxl_person_ddim_1000\n",
    "    orig_dir_name = 'sdxl_person_ddim_1000'\n",
    "elif class_word == 'woman':\n",
    "    !ghclone https://github.com/yushan777/SD-Regularization-Images/tree/main/sdxl_woman_ddim_1000\n",
    "    orig_dir_name = 'sdxl_woman_ddim_1000'\n",
    "elif class_word == 'man':\n",
    "    !ghclone https://github.com/yushan777/SD-Regularization-Images/tree/main/sdxl_man_ddim_1000\n",
    "    orig_dir_name = 'sdxl_man_ddim_1000'\n",
    "    \n",
    "\n",
    "if len(orig_dir_name) > 0:\n",
    "    # first make sure reg dir is empty, by emptying it\n",
    "    for filename in os.listdir(reg_dir):\n",
    "        file_path = os.path.join(reg_dir, filename)\n",
    "        try:\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.unlink(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print('Failed to delete %s. Reason: %s' % (file_path, e))\n",
    "            \n",
    "\n",
    "    # now move images to reg folder\n",
    "    print(\"Moving images to {reg_dir}\")\n",
    "    file_names = os.listdir(orig_dir_name)\n",
    "        \n",
    "    for file_name in file_names:\n",
    "        shutil.move(os.path.join(orig_dir_name, file_name), reg_dir)\n",
    "\n",
    "    # back to parent folder\n",
    "    %cd /workspace/kohya_ss\n",
    "\n",
    "    print(f\"{bcolors.GREEN}Finished downloading regularization images.{bcolors.ENDC}\")\n",
    "else:\n",
    "    print(f\"{bcolors.RED}Your class {class_word} does not match any available pre-made sets. Nothing downloaded.{bcolors.ENDC}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a446f2c4-984a-48db-be94-3d0bfba0f57c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 6. Check Dataset Folders\n",
    "# ====================================================\n",
    "# remove any non-image files & warn if any additional folders exist\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "folder_path = f'{training_dir}'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = glob(folder_path + '/*', recursive=False)\n",
    "\n",
    "# Iterate over the files and delete the ones that are not JPG or PNG\n",
    "for file_path in files:\n",
    "    if not (file_path.endswith('.jpg') or file_path.endswith('.png')):\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            print(f'{bcolors.BOLD}{bcolors.RED} Unexpected folder: \\'{file_path}\\' was found in training images folder path.  Check and remove it.{bcolors.ENDC}')\n",
    "\n",
    "# force remove hidden .ipynb_checkpoints folder in images folder. \n",
    "if os.path.exists(f'{folder_path}/.ipynb_checkpoints'):\n",
    "    shutil.rmtree(f'{folder_path}/.ipynb_checkpoints')\n",
    "\n",
    "# ====================================================\n",
    "# delete any non-image files & warn if any additional folders\n",
    "\n",
    "folder_path = f'{reg_dir}'\n",
    "\n",
    "# Get a list of all files in the folder\n",
    "files = glob(folder_path + '/*', recursive=False)\n",
    "\n",
    "# Iterate over the files and delete the ones that are not JPG or PNG\n",
    "for file_path in files:\n",
    "    if not (file_path.endswith('.jpg') or file_path.endswith('.png')):\n",
    "        if os.path.isfile(file_path):\n",
    "            os.remove(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            print(f'{bcolors.BOLD}{bcolors.RED} Unexpected folder: \\'{file_path}\\' was found in training images folder path.  Check and remove it.{bcolors.ENDC}')\n",
    "\n",
    "# force remove hidden .ipynb_checkpoints folder in images folder. \n",
    "if os.path.exists(f'{folder_path}/.ipynb_checkpoints'):\n",
    "    shutil.rmtree(f'{folder_path}/.ipynb_checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43b30d-afd9-450f-a7fb-e897407c6706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 7. Configure Accelerate With defaults\n",
    "!accelerate config default --mixed_precision \"bf16\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e3acb2-df65-4515-b00e-4d002be7f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. START TRAINING\n",
    "\n",
    "max_steps = 2000\n",
    "learning_rate = 1e-5 \n",
    "save_every_n_steps = 1000\n",
    "\n",
    "!accelerate launch --num_cpu_threads_per_process=2 \"./sdxl_train.py\" \\\n",
    "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
    "  --train_data_dir=\"{training_root_dir}\" \\\n",
    "  --reg_data_dir=\"{regularization_root_dir}\" \\\n",
    "  --output_dir=\"{output_dir}\" \\\n",
    "  --output_name=\"{project_name}\" \\\n",
    "  --save_model_as=\"safetensors\" \\\n",
    "  --train_batch_size=2 \\\n",
    "  --max_train_steps={max_steps} \\\n",
    "  --save_every_n_steps={save_every_n_steps} \\\n",
    "  --optimizer_type=\"adafactor\" \\\n",
    "  --optimizer_args scale_parameter=False relative_step=False warmup_init=False \\\n",
    "  --xformers \\\n",
    "  --cache_latents \\\n",
    "  --lr_scheduler=\"constant_with_warmup\" \\\n",
    "  --lr_warmup_steps=100 \\\n",
    "  --learning_rate={learning_rate} \\\n",
    "  --max_grad_norm=0.0 \\\n",
    "  --train_text_encoder \\\n",
    "  --resolution=\"1024,1024\" \\\n",
    "  --save_precision=\"fp16\" \\\n",
    "  --save_n_epoch_ratio=1 \\\n",
    "  --max_data_loader_n_workers=1 \\\n",
    "  --persistent_data_loader_workers \\\n",
    "  --mixed_precision=\"bf16\" \\\n",
    "  --full_bf16 \\\n",
    "  --logging_dir=\"logs\" \\\n",
    "  --log_prefix=\"last\" \\\n",
    "  --gradient_checkpointing \\\n",
    "  --sample_sampler=\"euler_a\" \\\n",
    "  --sample_prompts=\"prompt.txt\" \\\n",
    "  --sample_every_n_steps=100\n",
    " \n",
    " # note you can edit the prompts in the file prompt.txt if you prefer something different. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44072bf-090f-4adf-bece-8f9d3b5db145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
